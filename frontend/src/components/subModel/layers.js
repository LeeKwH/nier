export const layers = {
    'Linear Layers':{
        'Linear':{
            'descript':{
                'Linear':"",
                'out_features':"size of each output sample",
                'bias':"If set to False, the layer will not learn an additive bias.",
            },
            'out_features':1,
            'bias':['True','False'],
        },
    },
    'Convolution Layers':{
        'Conv1d':{
            'descript':{
                'Conv1d':"",
                'out_channels':"Number of channels produced by the convolution",
                'kernel_size':"Size of the convolving kernel",
                'stride':"Stride of the convolution.",
                'padding':"Padding added to both sides of the input.",
                'dilation':"Spacing between kernel elements.",
                'groups':"Number of blocked connections from input channels to output channels.",
                'bias':"If True, adds a learnable bias to the output.",
                'padding_mode':"'zeros', 'reflect', 'replicate' or 'circular'.",
            },
            'out_channels':1,
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'dilation':1,
            'groups':1,
            'bias':['True','False'],
            'padding_mode':['zeros','reflect','replicate','circular'],
        },
        'Conv2d':{
            'descript':{
                'Conv2d':"",
                'out_channels':"Number of channels produced by the convolution",
                'kernel_size':"Size of the convolving kernel",
                'stride':"Stride of the convolution.",
                'padding':"Padding added to both sides of the input.",
                'dilation':"Spacing between kernel elements.",
                'groups':"Number of blocked connections from input channels to output channels.",
                'bias':"If True, adds a learnable bias to the output.",
                'padding_mode':"'zeros', 'reflect', 'replicate' or 'circular'.",
            },
            'out_channels':1,
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'dilation':1,
            'groups':1,
            'bias':['True','False'],
            'padding_mode':['zeros','reflect','replicate','circular'],
        },
        'Conv3d':{
            'descript':{
                'Conv3d':"",
                'out_channels':"Number of channels produced by the convolution",
                'kernel_size':"Size of the convolving kernel",
                'stride':"Stride of the convolution.",
                'padding':"Padding added to both sides of the input.",
                'dilation':"Spacing between kernel elements.",
                'groups':"Number of blocked connections from input channels to output channels.",
                'bias':"If True, adds a learnable bias to the output.",
                'padding_mode':"'zeros', 'reflect', 'replicate' or 'circular'.",
            },
            'out_channels':1,
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'dilation':1,
            'groups':1,
            'bias':['True','False'],
            'padding_mode':['zeros','reflect','replicate','circular'],
        },
        'ConvTranspose1d':{
            'descript':{
                'ConvTranspose1d':"",
                'out_channels':"Number of channels produced by the convolution",
                'kernel_size':"Size of the convolving kernel",
                'stride':"Stride of the convolution.",
                'padding':"dilation * (kernel_size - 1) - padding zero-padding will be added to both sides of the input.",
                'output_padding':"Additional size added to one side of the output shape.",
                'groups':"Number of blocked connections from input channels to output channels.",
                'bias':"If True, adds a learnable bias to the output.",
                'dilation':"Spacing between kernel elements.",
                'padding_mode':"'zeros', 'reflect', 'replicate' or 'circular'.",
            },
            'out_channels':1,
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'output_padding':0,
            'groups':1,
            'bias':['True','False'],
            'dilation':1,
            'padding_mode':['zeros','reflect','replicate','circular'],
        },
        'ConvTranspose2d':{
            'descript':{
                'ConvTranspose2d':"",
                'out_channels':"Number of channels produced by the convolution",
                'kernel_size':"Size of the convolving kernel",
                'stride':"Stride of the convolution.",
                'padding':"dilation * (kernel_size - 1) - padding zero-padding will be added to both sides of the input.",
                'output_padding':"Additional size added to one side of the output shape.",
                'groups':"Number of blocked connections from input channels to output channels.",
                'bias':"If True, adds a learnable bias to the output.",
                'dilation':"Spacing between kernel elements.",
                'padding_mode':"'zeros', 'reflect', 'replicate' or 'circular'.",
            },
            'out_channels':1,
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'output_padding':0,
            'groups':1,
            'bias':['True','False'],
            'dilation':1,
            'padding_mode':['zeros','reflect','replicate','circular'],
        },
        'ConvTranspose3d':{
            'descript':{
                'ConvTranspose3d':"",
                'out_channels':"Number of channels produced by the convolution",
                'kernel_size':"Size of the convolving kernel",
                'stride':"Stride of the convolution.",
                'padding':"dilation * (kernel_size - 1) - padding zero-padding will be added to both sides of the input.",
                'output_padding':"Additional size added to one side of the output shape.",
                'groups':"Number of blocked connections from input channels to output channels.",
                'bias':"If True, adds a learnable bias to the output.",
                'dilation':"Spacing between kernel elements.",
                'padding_mode':"'zeros', 'reflect', 'replicate' or 'circular'.",
            },
            'out_channels':1,
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'output_padding':0,
            'groups':1,
            'bias':['True','False'],
            'dilation':1,
            'padding_mode':['zeros','reflect','replicate','circular'],
        },
        'Fold':{
            'descript':{
                'Fold':"",
                'output_size':"output size",
                'kernel_size':"kernel size",
                'dilation':"dilation",
                'padding':"padding",
                'stride':"stride",
            },
            'output_size':1,
            'kernel_size':1,
            'dilation':1,
            'padding':0,
            'stride':1,
        },
        'Unfold':{
            'descript':{
                'Unfold':"",
                'kernel_size':"kernel size",
                'dilation':"dilation",
                'padding':"padding",
                'stride':"stride",
            },
            'kernel_size':1,
            'dilation':1,
            'padding':0,
            'stride':1,
        },
    },
    'Deep Layers':{
        'Flatten':{
            'descript':{
                'Flatten':"",
                'start_dim':"first dim to flatten",
                'end_dim':"last dim to flatten",
            },
            'start_dim':1,
            'end_dim':-1,
        },
        'Unflatten':{
            'descript':{
                'Unflatten':"",
                'dim':"dim to unflatten",
                'unflattened_size':"sizes of unflattened dimensions",
            },
            'dim':1,
            'unflattened_size':1,
        },
    },
    'Recurrent Layers':{
        'RNN':{
            'descript':{
                'RNN':"",
                'out_size':"The number of features in the hidden state",
                'num_layers':"Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results.",
                'nonlinearity':"The non-linearity to use.",
                'bias':"If False, then the layer does not use bias weights b_ih and b_hh.",
                'batch_first':"If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details.",
                'dropout':"If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout.",
                'bidirectional':"If True, becomes a bidirectional RNN.",
            },
            'out_size':1,
            'num_layers':1,
            'nonlinearity':['Tanh','ReLU'],
            'bias':['True','False'],
            'batch_first':['False','True'],
            'dropout':0,
            'bidirectional':['False','True'],
        },
        'LSTM':{
            'descript':{
                'LSTM':"",
                'hidden_size':"The number of features in the hidden state",
                'num_layers':"Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results.",
                'bias':"If False, then the layer does not use bias weights b_ih and b_hh.",
                'batch_first':"If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details.",
                'dropout':"If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout.",
                'bidirectional':"If True, becomes a bidirectional LSTM.",
                'proj_size':"If > 0, will use LSTM with projections of corresponding size.",
            },
            'hidden_size':1,
            'num_layers':1,
            'bias':['True','False'],
            'batch_first':['True','False'],
            'dropout':0,
            'bidirectional':['False','True'],
            'proj_size':0,
        },
        'GRU':{
            'descript':{
                'GRU':"",
                'out_size':"The number of features in the hidden state",
                'num_layers':"Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results.",
                'nonlinearity':"The non-linearity to use.",
                'bias':"If False, then the layer does not use bias weights b_ih and b_hh.",
                'batch_first':"If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details.",
                'dropout':"If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout.",
                'bidirectional':"If True, becomes a bidirectional GRU.",
            },
            'out_size':1,
            'num_layers':0,
            'nonlinearity':['Tanh','ReLU'],
            'bias':['True','False'],
            'batch_first':['False','True'],
            'dropout':0,
            'bidirectional':['False','True'],
        },
        'RNNCell':{
            'descript':{
                'RNNCell':"",
                'hidden_size':"The number of features in the hidden state",
                'bias':"If False, then the layer does not use bias weights b_ih and b_hh.",
                'nonlinearity':"The non-linearity to use.",
            },
            'hidden_size':1,
            'bias':['True','False'],
            'nonlinearity':['Tanh','ReLU'],
        },
        'LSTMCell':{
            'descript':{
                'LSTMCell':"",
                'hidden_size':"The number of features in the hidden state",
                'bias':"If False, then the layer does not use bias weights b_ih and b_hh.",
            },
            'hidden_size':1,
            'bias':['True','False'],
        },
        'GRUCell':{
            'descript':{
                'GRUCell':"",
                'hidden_size':"The number of features in the hidden state",
                'bias':"If False, then the layer does not use bias weights b_ih and b_hh.",
            },
            'hidden_size':1,
            'bias':['True','False'],
        },

    },
    
    'Pooling Layers':{
        'Avgpool1d':{
            'descript':{
                'Avgpool1D':"",
                'kernel_size':"the size of the window",
                'stride':"the stride of the window. Default value is kernel_size",
                'padding':"implicit zero padding to be added on both sides",
                'ceil_mode':"when True, will use ceil instead of floor to compute the output shape",
                'count_include_pad':"when True, will include the zero-padding in the averaging calculation",
            },
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'ceil_mode':['False','True'],
            'count_include_pad':['True','False'],
        },
        'Avgpool2D':{
            'descript':{
                'Avgpool2D':"",
                'kernel_size':"the size of the window",
                'stride':"the stride of the window. Default value is kernel_size",
                'padding':"implicit zero padding to be added on both sides",
                'ceil_mode':"when True, will use ceil instead of floor to compute the output shape",
                'count_include_pad':"when True, will include the zero-padding in the averaging calculation",
                'divisor_override':"if specified, it will be used as divisor, otherwise size of the pooling region will be used.",
            },
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'ceil_mode':['False','True'],
            'count_include_pad':['True','False'],
            'divisor_override':0,
        },
        'Avgpool3D':{
            'descript':{
                'Avgpool3D':"",
                'kernel_size':"the size of the window",
                'stride':"the stride of the window. Default value is kernel_size",
                'padding':"implicit zero padding to be added on both sides",
                'ceil_mode':"when True, will use ceil instead of floor to compute the output shape",
                'count_include_pad':"when True, will include the zero-padding in the averaging calculation",
                'divisor_override':"if specified, it will be used as divisor, otherwise size of the pooling region will be used.",
            },
            'kernel_size':1,
            'stride':0,
            'padding':0,
            'ceil_mode':['False','True'],
            'count_include_pad':['True','False'],
            'divisor_override':0,
        },
        'MaxPool1d':{
            'descript':{
                'MaxPool1d':"",
                'kernel_size':"the size of the window, must be > 0.",
                'stride':"the stride of the window, must be > 0. Default value is kernel_size",
                'padding':"Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.",
                'dilation':"The stride between elements within a sliding window, must be > 0.",
                'return_indices':"If True, will return the argmax along with the max values. Useful for torch.nn.MaxUnpool1d later",
                'ceil_mode':"If True, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.",
            },
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'dilation':1,
            'return_indices':['True','False'],
            'ceil_mode':['False','True'],
        },
        'MaxPool2d':{
            'descript':{
                'MaxPool2d':"",
                'kernel_size':"the size of the window, must be > 0.",
                'stride':"the stride of the window, must be > 0. Default value is kernel_size",
                'padding':"Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.",
                'dilation':"The stride between elements within a sliding window, must be > 0.",
                'return_indices':"If True, will return the argmax along with the max values. Useful for torch.nn.MaxUnpool1d later",
                'ceil_mode':"If True, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.",
            },
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'dilation':1,
            'return_indices':['True','False'],
            'ceil_mode':['False','True'],
        },
        'MaxPool3d':{
            'descript':{
                'MaxPool3d':"",
                'kernel_size':"the size of the window, must be > 0.",
                'stride':"the stride of the window, must be > 0. Default value is kernel_size",
                'padding':"Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.",
                'dilation':"The stride between elements within a sliding window, must be > 0.",
                'return_indices':"If True, will return the argmax along with the max values. Useful for torch.nn.MaxUnpool1d later",
                'ceil_mode':"If True, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.",
            },
            'kernel_size':1,
            'stride':1,
            'padding':0,
            'dilation':1,
            'return_indices':['False','True'],
            'ceil_mode':['False','True'],
        },
        'MaxUnpool1d':{
            'descript':{
                'MaxUnpool1d':"",
                'kernel_size':"the size of the window, must be > 0.",
                'stride':"the stride of the window, must be > 0. Default value is kernel_size",
                'padding':"Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.",
            },
            'kernel_size':1,
            'stride':1,
            'padding':0,
        },
        'MaxUnpool2d':{
            'descript':{
                'MaxUnpool2d':"",
                'kernel_size':"the size of the window, must be > 0.",
                'stride':"the stride of the window, must be > 0. Default value is kernel_size",
                'padding':"Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.",
            },
            'kernel_size':1,
            'stride':1,
            'padding':0,
        },
        'MaxUnpool3d':{
            'descript':{
                'MaxUnpool3d':"",
                'kernel_size':"the size of the window, must be > 0.",
                'stride':"the stride of the window, must be > 0. Default value is kernel_size",
                'padding':"Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.",
            },
            'kernel_size':1,
            'stride':1,
            'padding':0,
        },
        'FractionalMaxPool2d':{
            'descript':{
                'FractionalMaxPool2d':"",
                'kernel_size':"the size of the window, must be > 0.",
                'output_size':"the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. If a tuple, the output size will match the input size, except in the batch dimension. If a single number, the output will have the same height and width as the input. For example, if the input is of shape: (N, C, H, W), and output_size is (H', W'), then the output will be of shape: (N, C, H', W').",
                'output_ratio':"the ratio of the target output size to the input size. It should be in the range (0, 1]. If output_ratio is not None, then output_size must be None.",
                'return_indices':"If True, will return the indices along with the outputs. Useful to pass to torch.nn.FractionalMaxPool2d_backward later",
            },
            'kernel_size':1,
            'output_size':0,
            'output_ratio':0.0,
            'return_indices':['False','True'],
        },
        'FractionalMaxPool3d':{
            'descript':{
                'FractionalMaxPool3d':"",
                'kernel_size':"the size of the window, must be > 0.",
                'output_size':"the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. If a tuple, the output size will match the input size, except in the batch dimension. If a single number, the output will have the same height and width as the input. For example, if the input is of shape: (N, C, H, W), and output_size is (H', W'), then the output will be of shape: (N, C, H', W').",
                'output_ratio':"the ratio of the target output size to the input size. It should be in the range (0, 1]. If output_ratio is not None, then output_size must be None.",
                'return_indices':"If True, will return the indices along with the outputs. Useful to pass to torch.nn.FractionalMaxPool3d_backward later",
            },
            'kernel_size':1,
            'output_size':0,
            'output_ratio':0.0,
            'return_indices':['False','True'],
        },
        'LPPool1d':{
            'descript':{
                'LPPool1d':"",
                'norm_type':"the norm to calculate distance with",
                'kernel_size':"the size of the window, must be > 0.",
                'stride':"the stride of the window, must be > 0. Default value is kernel_size",
                'ceil_mode':"If True, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.",
            },
            'norm_type':2,
            'kernel_size':1,
            'stride':1,
            'ceil_mode':['False','True'],
        },
        'LPPool2d':{
            'descript':{
                'LPPool2d':"",
                'norm_type':"the norm to calculate distance with",
                'kernel_size':"the size of the window, must be > 0.",
                'stride':"the stride of the window, must be > 0. Default value is kernel_size",
                'ceil_mode':"If True, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.",
            },
            'norm_type':2,
            'kernel_size':1,
            'stride':1,
            'ceil_mode':['False','True'],
        },
        'AdaptiveMaxPool1d':{
            'descript':{
                'AdaptiveMaxPool1d':"",
                'output_size':"the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. If a tuple, the output size will match the input size, except in the batch dimension. If a single number, the output will have the same height and width as the input. For example, if the input is of shape: (N, C, H, W), and output_size is (H', W'), then the output will be of shape: (N, C, H', W').",
                'return_indices':"If True, will return the indices along with the outputs. Useful to pass to torch.nn.AdaptiveMaxPool1d_backward later",
            },
            'output_size':1,
            'return_indices':['False','True'],
        },
        'AdaptiveMaxPool2d':{
            'descript':{
                'AdaptiveMaxPool1d':"",
                'output_size':"the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. If a tuple, the output size will match the input size, except in the batch dimension. If a single number, the output will have the same height and width as the input. For example, if the input is of shape: (N, C, H, W), and output_size is (H', W'), then the output will be of shape: (N, C, H', W').",
                'return_indices':"If True, will return the indices along with the outputs. Useful to pass to torch.nn.AdaptiveMaxPool1d_backward later",
            },
            'output_size':1,
            'return_indices':['False','True'],
        },
        'AdaptiveMaxPool3d':{
            'descript':{
                'AdaptiveMaxPool1d':"",
                'output_size':"the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. If a tuple, the output size will match the input size, except in the batch dimension. If a single number, the output will have the same height and width as the input. For example, if the input is of shape: (N, C, H, W), and output_size is (H', W'), then the output will be of shape: (N, C, H', W').",
                'return_indices':"If True, will return the indices along with the outputs. Useful to pass to torch.nn.AdaptiveMaxPool1d_backward later",
            },
            'output_size':1,
            'return_indices':['False','True'],
        },
        'AdaptiveAvgPool1d':{
            'descript':{
                'AdaptiveAvgPool1d':"",
                'output_size':"the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. If a tuple, the output size will match the input size, except in the batch dimension. If a single number, the output will have the same height and width as the input. For example, if the input is of shape: (N, C, H, W), and output_size is (H', W'), then the output will be of shape: (N, C, H', W').",
            },
            'output_size':1,
        },
        'AdaptiveAvgPool2d':{
            'descript':{
                'AdaptiveAvgPool1d':"",
                'output_size':"the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. If a tuple, the output size will match the input size, except in the batch dimension. If a single number, the output will have the same height and width as the input. For example, if the input is of shape: (N, C, H, W), and output_size is (H', W'), then the output will be of shape: (N, C, H', W').",
            },
            'output_size':1,
        },
        'AdaptiveAvgPool3d':{
            'descript':{
                'AdaptiveAvgPool1d':"",
                'output_size':"the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. If a tuple, the output size will match the input size, except in the batch dimension. If a single number, the output will have the same height and width as the input. For example, if the input is of shape: (N, C, H, W), and output_size is (H', W'), then the output will be of shape: (N, C, H', W').",
            },
            'output_size':1,
        },

    },
    'Padding Layers':{
        'ReflectionPad1d':{
            'descript':{
                'ReflectionPad1d':"Applies Reflection Padding to the input.",
                'padding':"the size of the padding. If is int, uses the same padding in all boundaries. If a 2-ple, uses (paddingLeft, paddingRight). If a 4-ple, uses (paddingLeft, paddingRight, paddingTop, paddingBottom).",
            },
            'padding':0,
        },
        'ReflectionPad2d':{
            'descript':{
                'ReflectionPad1d':"Applies Reflection Padding to the input.",
                'padding':"the size of the padding. If is int, uses the same padding in all boundaries. If a 2-ple, uses (paddingLeft, paddingRight). If a 4-ple, uses (paddingLeft, paddingRight, paddingTop, paddingBottom).",
            },
            'padding':0,
        },
        'ReflectionPad3d':{
            'descript':{
                'ReflectionPad1d':"Applies Reflection Padding to the input.",
                'padding':"the size of the padding. If is int, uses the same padding in all boundaries. If a 2-ple, uses (paddingLeft, paddingRight). If a 4-ple, uses (paddingLeft, paddingRight, paddingTop, paddingBottom).",
            },
            'padding':0,
        },
        'ReplicationPad1d':{
            'descript':{
                'ReplicationPad1d':"Applies Replication Padding to the input.",
                'padding':"the size of the padding. If is int, uses the same padding in all boundaries. If a 2-ple, uses (paddingLeft, paddingRight). If a 4-ple, uses (paddingLeft, paddingRight, paddingTop, paddingBottom).",
            },
            'padding':0,
        },
        'ReplicationPad2d':{
            'descript':{
                'ReplicationPad1d':"Applies Replication Padding to the input.",
                'padding':"the size of the padding. If is int, uses the same padding in all boundaries. If a 2-ple, uses (paddingLeft, paddingRight). If a 4-ple, uses (paddingLeft, paddingRight, paddingTop, paddingBottom).",
            },
            'padding':0,
        },
        'ReplicationPad3d':{
            'descript':{
                'ReplicationPad1d':"Applies Replication Padding to the input.",
                'padding':"the size of the padding. If is int, uses the same padding in all boundaries. If a 2-ple, uses (paddingLeft, paddingRight). If a 4-ple, uses (paddingLeft, paddingRight, paddingTop, paddingBottom).",
            },
            'padding':0,
        },
        'ZeroPad2d':{
            'descript':{
                'ZeroPad2d':"Pads the input tensor boundaries with zero.",
                'padding':"the size of the padding. If is int, uses the same padding in all boundaries. If a 2-ple, uses (paddingLeft, paddingRight). If a 4-ple, uses (paddingLeft, paddingRight, paddingTop, paddingBottom).",
            },
            'padding':0,
        },
        'ConstantPad1d':{
            'descript':{
                'ConstantPad1d':"Pads the input tensor boundaries with a constant value.",
                'padding':"the size of the padding. If is int, uses the same padding in all boundaries. If a 2-ple, uses (paddingLeft, paddingRight). If a 4-ple, uses (paddingLeft, paddingRight, paddingTop, paddingBottom).",
                'value':"the constant value used for padding.",
            },
            'padding':0,
            'value':0,
        },
        'ConstantPad2d':{
            'descript':{
                'ConstantPad1d':"Pads the input tensor boundaries with a constant value.",
                'padding':"the size of the padding. If is int, uses the same padding in all boundaries. If a 2-ple, uses (paddingLeft, paddingRight). If a 4-ple, uses (paddingLeft, paddingRight, paddingTop, paddingBottom).",
                'value':"the constant value used for padding.",
            },
            'padding':0,
            'value':0,
        },
        'ConstantPad3d':{
            'descript':{
                'ConstantPad1d':"Pads the input tensor boundaries with a constant value.",
                'padding':"the size of the padding. If is int, uses the same padding in all boundaries. If a 2-ple, uses (paddingLeft, paddingRight). If a 4-ple, uses (paddingLeft, paddingRight, paddingTop, paddingBottom).",
                'value':"the constant value used for padding.",
            },
            'padding':0,
            'value':0,
        },
    },
    'Non-linear Activation':{
        'ReLU':{
            'descript':{
                'ReLU':"",
            },
        },
        'Hardtanh':{
            'descript':{
                'Hardtanh':"",
                'min_val':"minimum value of the linear region range.",
                'max_val':"aximum value of the linear region range.",
                'inplace':"can optionally do the operation in-place.",
            },
            'min_val':-1.0,
            'max_val':1.0,
            'inplace':['False','True'],
        },
        'ERU':{
            'descript':{
                'ERU':"",
                'alpha':"the alpha(α) value for the ELU formulation",
                'inplace':"can optionally do the operation in-place.",
            },
            'alpha':1.0,
            'inplace':['False','True'],
        },
        'Leaky_ReLU':{
            'descript':{
                'Leaky_ReLU':"",
                'negative_slope':"Controls the angle of the negative slope.",
                'inplace':"can optionally do the operation in-place.",
            },
            'negative_slope':0.01,
            'inplace':['False','True'],
        },
        'RReLU':{
            'descript':{
                'RReLU':"",
                'lower':"lower bound of the uniform distribution.",
                'upper':"upper bound of the uniform distribution.",
                'inplace':"can optionally do the operation in-place.",
            },
            'lower':0.125,
            'upper':0.333333333,
            'inplace':['False','True'],
        },
        'LogSigmoid':{
            'descript':{
                'LogSigmoid':"",
            },
        },
        'Softsign':{
            'descript':{
                'Softsign':"",
            },
        },
        'Tanh':{
            'descript':{
                'Tanh':"",
            },
        },
        'Sigmoid':{
            'descript':{
                'Sigmoid':"",
            },
        },
        'AdaptiveLogSoftmaxWithLoss':{
            'descript':{
                'AdaptiveLogSoftmaxWithLoss':"",
                'n_classes':"number of classes.",
                'cutoffs':"cutoffs for each cluster.",
                'div_value':"divisor for the cluster sizes.",
                'head_bias':"if True, adds a bias to the head.",
            },
            'n_classes':1,
            'cutoffs':1,
            'div_value':1.0,
            'head_bias':['True','False'],
        },
    },
    'Normalization Layers':{
        'BatchNorm1d':{
            'descript':{
                'BatchNorm1d':"",
                'num_features':"C from an expected input of size (N,C,L)",
                'eps':"a value added to the denominator for numerical stability. Default: 1e-5",
                'momentum':"the value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1",
                'affine':"a boolean value that when set to True, this module has learnable affine parameters. Default: True",
                'track_running_stats':"a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True",
            },
            'num_features':1,
            'eps':1e-5,
            'momentum':0.1,
            'affine':['True','False'],
            'track_running_stats':['True','False'],
        },
        'BatchNorm2d':{
            'descript':{
                'BatchNorm2d':"",
                'num_features':"C from an expected input of size (N,C,H,W)",
                'eps':"a value added to the denominator for numerical stability. Default: 1e-5",
                'momentum':"the value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1",
                'affine':"a boolean value that when set to True, this module has learnable affine parameters. Default: True",
                'track_running_stats':"a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True",
            },
            'num_features':1,
            'eps':1e-5,
            'momentum':0.1,
            'affine':['True','False'],
            'track_running_stats':['True','False'],
        },
        'BatchNorm3d':{
            'descript':{
                'BatchNorm3d':"",
                'num_features':"C from an expected input of size (N,C,D,H,W)",
                'eps':"a value added to the denominator for numerical stability. Default: 1e-5",
                'momentum':"the value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1",
                'affine':"a boolean value that when set to True, this module has learnable affine parameters. Default: True",
                'track_running_stats':"a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True",
            },
            'num_features':1,
            'eps':1e-5,
            'momentum':0.1,
            'affine':['True','False'],
            'track_running_stats':['True','False'],
        },
        'InstanceNorm1d':{
            'descript':{
                'InstanceNorm1d':"",
                'num_features':"C from an expected input of size (N,C,L)",
                'eps':"a value added to the denominator for numerical stability. Default: 1e-5",
                'momentum':"the value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1",
                'affine':"a boolean value that when set to True, this module has learnable affine parameters. Default: True",
                'track_running_stats':"a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True",
            },
            'num_features':1,
            'eps':1e-5,
            'momentum':0.1,
            'affine':['False','True'],
            'track_running_stats':['False','True'],
        },
        'InstanceNorm2d':{
            'descript':{
                'InstanceNorm2d':"",
                'num_features':"C from an expected input of size (N,C,H,W)",
                'eps':"a value added to the denominator for numerical stability. Default: 1e-5",
                'momentum':"the value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1",
                'affine':"a boolean value that when set to True, this module has learnable affine parameters. Default: True",
                'track_running_stats':"a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True",
            },
            'num_features':1,
            'eps':1e-5,
            'momentum':0.1,
            'affine':['False','True'],
            'track_running_stats':['False','True'],
        },
        'InstanceNorm3d':{
            'descript':{
                'InstanceNorm3d':"",
                'num_features':"C from an expected input of size (N,C,D,H,W)",
                'eps':"a value added to the denominator for numerical stability. Default: 1e-5",
                'momentum':"the value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1",
                'affine':"a boolean value that when set to True, this module has learnable affine parameters. Default: True",
                'track_running_stats':"a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True",
            },
            'num_features':1,
            'eps':1e-5,
            'momentum':0.1,
            'affine':['False','True'],
            'track_running_stats':['False','True'],
        },
        'LayerNorm':{
            'descript':{
                'LayerNorm':"",
                'normalized_shape':"input shape from an expected input of size",
                'eps':"a value added to the denominator for numerical stability. Default: 1e-5",
                'elementwise_affine':"a boolean value that when set to True, this module has learnable per-element affine parameters initialized to ones (for weights) and zeros (for biases). Default: True",
            },
            'normalized_shape':1,
            'eps':1e-5,
            'elementwise_affine':['True','False'],
        },
        'GroupNorm':{
            'descript':{
                'GroupNorm':"",
                'num_groups':"number of groups to separate the channels into",
                'num_channels':"number of channels expected in input",
                'eps':"a value added to the denominator for numerical stability. Default: 1e-5",
                'affine':"a boolean value that when set to True, this module has learnable per-element affine parameters initialized to ones (for weights) and zeros (for biases). Default: True",
            },
            'num_groups':1,
            'num_channels':1,
            'eps':1e-5,
            'affine':['True','False'],
        },
        'SyncBatchNorm':{
            'descript':{
                'SyncBatchNorm':"",
                'num_features':"C from an expected input of size (N,C,H,W)",
                'eps':"a value added to the denominator for numerical stability. Default: 1e-5",
                'momentum':"the value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1",
                'affine':"a boolean value that when set to True, this module has learnable affine parameters. Default: True",
                'track_running_stats':"a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True",
            },
            'num_features':1,
            'eps':1e-5,
            'momentum':0.1,
            'affine':['True','False'],
            'track_running_stats':['True','False'],
        }
    },
    'Dropout Layers':{
        'Dropout':{
            'descript':{
                'Dropout':"",
                'p':"probability of an element to be zeroed.",
                'inplace':"If set to True, will do this operation in-place.",
            },
            'p':0.5,
            'inplace':['False','True'],
        },
        'AlphaDropout':{
            'descript':{
                'AlphaDropout':"",
                'p':"probability of an element to be zeroed.",
                'inplace':"If set to True, will do this operation in-place.",
            },
            'p':0.5,
            'inplace':['False','True'],
        },
        'FeatureAlphaDropout':{
            'descript':{
                'FeatureAlphaDropout':"",
                'p':"probability of an element to be zeroed.",
                'inplace':"If set to True, will do this operation in-place.",
            },
            'p':0.5,
            'inplace':['False','True'],
        }

    },
    
    'Merge':{
        'Merge':{
            'descript':{
                'Merge':"Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty."
            }
        }
    }
}